{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5084f184-812f-4172-abe8-f5be5a46711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 4], [3, 6], [4, 5], [6, 7], [3, 3], [2, 5], [5, 2]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "# We are gonna use Scikit's LinearRegression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Your input data, X and Y are lists (or Numpy Arrays)\n",
    "x = [[2,4],[3,6],[4,5],[6,7],[3,3],[2,5],[5,2]]\n",
    "y = [14,21,22,32,15,16,19]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2079f728-9646-47aa-afb0-2785230a4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = np.array(y)\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49dbf3c8-5d96-43d6-930b-dca14641bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [3, 6],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [3, 3],\n",
       "       [2, 5],\n",
       "       [5, 2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "540ee964-7a26-4043-94d2-8ff8fe520f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 21, 22, 32, 15, 16, 19])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc5279f3-1033-4405-ae1d-b89bdad111d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model then train it on the data\n",
    "import numpy as np\n",
    "genius_regression_model = LinearRegression()\n",
    "genius_regression_model.fit(x,y)\n",
    "y_pred = genius_regression_model.predict(x)\n",
    "# Predict the corresponding value of Y for X = [8,4]\n",
    "# print(genius_regression_model.predict([8,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6241d7b5-99de-4165-9c9c-c4f1ea6dd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.409331921515509e-30\n",
      "2.325797050801189e-15\n",
      "-33.69471359707098\n",
      "1.522591576628786e-15\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "genius_regression_model.predict(np.array([[8,4]]))\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(mean_squared_error(y,y_pred))\n",
    "print(np.sqrt(mean_squared_error(y,y_pred)))\n",
    "print(np.log(np.sqrt(mean_squared_error(y,y_pred))))\n",
    "print(mean_absolute_error(y,y_pred))\n",
    "print(r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8b63b2e-8dac-4786-aef5-541f23ea1af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjusted_r2_score(actual, predictions, num_pred, num_samples):\n",
    "    n = num_samples\n",
    "    k = num_pred\n",
    "    r2 = r2_score(actual, predictions)\n",
    "    adjusted_r2 = 1 - ((1-r2) * ((n-1)/(n-k-1)))\n",
    "    return adjusted_r2\n",
    "adjusted_r2_score(y,y_pred,x.shape[0],x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21b6fb1f-50f4-4518-a483-52e1cc0ed4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 21, 22, 32, 15, 16, 19])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2b417b48-9b69-445b-b069-606d682df395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 21., 22., 32., 15., 16., 19.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bfccba8c-074a-4ffe-ab29-ae55077f922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1.],\n",
       "       [  1.,   4.,  16.],\n",
       "       [  1.,   7.,  49.],\n",
       "       [  1.,  13., 169.],\n",
       "       [  1.,  10., 100.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x = [[1],[4],[7],[13],[10]]\n",
    "# x = x.reshape(-1,1)\n",
    "# Y1 = 10 + 6*x\n",
    "y1 = np.array([16, 34, 52, 88, 70])\n",
    "# Y2 = x*x = x^2\n",
    "y2 = [1, 16, 49, 169, 100]\n",
    "poly  = PolynomialFeatures(degree = 2)\n",
    "poly_x = poly.fit_transform(x)\n",
    "poly_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "37c3f402-6466-45da-8008-84e8e776a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5045155184375138e-27\n",
      "3.8788084748251156e-14\n",
      "-30.88066328956175\n",
      "3.2684965844964606e-14\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "genius_regression_model = LinearRegression()\n",
    "genius_regression_model.fit(poly_x, y1)\n",
    "y_pred = genius_regression_model.predict(poly_x)\n",
    "print(mean_squared_error(y1,y_pred))\n",
    "print(np.sqrt(mean_squared_error(y1,y_pred)))\n",
    "print(np.log(np.sqrt(mean_squared_error(y1,y_pred))))\n",
    "print(mean_absolute_error(y1,y_pred))\n",
    "print(r2_score(y1,y_pred))\n",
    "print(adjusted_r2_score(y1,y_pred,poly_x.shape[0],poly_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d42e516-c881-45fc-9e20-7317a0957340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.36586989986883e-29\n",
      "9.146512942028142e-15\n",
      "-32.32540368749192\n",
      "5.595524044110789e-15\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y2 = [1, 16, 49, 169, 100]\n",
    "\n",
    "# This will convert X into \n",
    "# [[1,1], [4,16], [7,49], .. etc]\n",
    "# Only 1st and 2nd degree, since degree=2\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "poly_x = pf.fit_transform(x)\n",
    "\n",
    "genius_regression_model.fit(poly_x, y2)\n",
    "genius_regression_model = LinearRegression()\n",
    "genius_regression_model.fit(poly_x, y2)\n",
    "y_pred = genius_regression_model.predict(poly_x)\n",
    "print(mean_squared_error(y2,y_pred))\n",
    "print(np.sqrt(mean_squared_error(y2,y_pred)))\n",
    "print(np.log(np.sqrt(mean_squared_error(y2,y_pred))))\n",
    "print(mean_absolute_error(y2,y_pred))\n",
    "print(r2_score(y2,y_pred))\n",
    "print(adjusted_r2_score(y2,y_pred,poly_x.shape[0],poly_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd382ec4-f93d-4061-8498-31b71daa136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.76084257031239\n",
      "10.380792001110146\n",
      "2.3399571755119783\n",
      "7.949112974776344\n",
      "0.833702403440876\n",
      "1.1108650643727493\n"
     ]
    }
   ],
   "source": [
    "x = [[1],[4],[7],[13],[10]]\n",
    "y1 = [16, 34, 52, 88, 70]\n",
    "y2 = [1, 16, 49, 169, 100]\n",
    "from sklearn import svm\n",
    "model = svm.SVR(kernel = 'poly')\n",
    "model.fit(x,y1)\n",
    "y_pred = model.predict(x)\n",
    "print(mean_squared_error(y1,y_pred))\n",
    "print(np.sqrt(mean_squared_error(y1,y_pred)))\n",
    "print(np.log(np.sqrt(mean_squared_error(y1,y_pred))))\n",
    "print(mean_absolute_error(y1,y_pred))\n",
    "print(r2_score(y1,y_pred))\n",
    "print(adjusted_r2_score(y1,y_pred,poly_x.shape[0],poly_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "596d478f-1cb3-4a19-8f47-b5143388bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.79693868070667\n",
      "10.573407146265893\n",
      "2.358342089120755\n",
      "8.08582179747286\n",
      "0.9702255942578282\n",
      "1.0198496038281146\n"
     ]
    }
   ],
   "source": [
    "x = [[1],[4],[7],[13],[10]]\n",
    "y1 = [16, 34, 52, 88, 70]\n",
    "y2 = [1, 16, 49, 169, 100]\n",
    "from sklearn import svm\n",
    "model = svm.SVR(kernel='poly')\n",
    "model.fit(x,y2)\n",
    "y_pred = model.predict(x)\n",
    "print(mean_squared_error(y2,y_pred))\n",
    "print(np.sqrt(mean_squared_error(y2,y_pred)))\n",
    "print(np.log(np.sqrt(mean_squared_error(y2,y_pred))))\n",
    "print(mean_absolute_error(y2,y_pred))\n",
    "print(r2_score(y2,y_pred))\n",
    "print(adjusted_r2_score(y2,y_pred,poly_x.shape[0],poly_x.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc143fa-7848-4f2a-8eb3-f660c6fe35a4",
   "metadata": {},
   "source": [
    "###What to Look For\n",
    "#RÂ² close to 1? Great job! Your model explains most of the variation.\n",
    "#Low MAE and RMSE? Your predictions are close to the actual values.\n",
    "#Residuals all over the place? Thatâs good â no obvious pattern means the model is solid.\n",
    "#Residuals showing a curve? Hmm, maybe the relationship isnât linear after all (time to explore other models).\n",
    "#And there you have it! ð Youâve not only built a model but also evaluated its performance like a pro. If things didnât go perfectly, donât worry â itâs all part of the learning process. Up next, weâll look at ways to tweak and improve your model. Keep going â youâre almost there! ðª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77443e02-c1ba-4245-b987-f03589da37aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
